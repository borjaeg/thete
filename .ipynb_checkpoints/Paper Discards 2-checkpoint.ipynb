{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import collections\n",
    "import os\n",
    "from time import time\n",
    "\n",
    "# Data Science\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import seaborn as sb\n",
    "\n",
    "# Natural Language processing\n",
    "import nltk\n",
    "\n",
    "# Algorithms / estimators\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "# Feature Extraction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Process\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from scipy import interp\n",
    "\n",
    "# Corpus\n",
    "from documentModel import DocumentModel as DM\n",
    "from export_results import *\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "def is_significant(model_1, model_2, significance = 0.05):\n",
    "    \n",
    "    p_value = stats.wilcoxon(recall_avg[model_1], recall_avg[model_2])[1]\n",
    "    print(p_value)\n",
    "    if p_value < significance:\n",
    "        print(\"It is statically significant\")\n",
    "    else:    \n",
    "        print(\"It is NOT statically significant\")\n",
    "\n",
    "def save_image(image, url='../images/', name = 'default'):\n",
    "    image.savefig(url + name)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = ['a', 'bajo', 'en', 'para','un', 'la', 'el', 'los', 'las', 'su', 'sus', 'través', 'al','con', \\\n",
    "             'más', 'muy', 'cual', 'poco', 'que']\n",
    "\n",
    "print(\"Transforming annotated files into training datasets...\")\n",
    "dm = DM()\n",
    "fito_dataset = dm.get_sentences(0)\n",
    "X, y = fito_dataset[\"data\"], fito_dataset[\"target\"]\n",
    "\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "fn_c = [1, 5, 10]\n",
    "fp_c = [1, 5, 10]\n",
    "\n",
    "colors = \"rgbmy\"\n",
    "i = 1\n",
    "plt.figure(figsize=(18, 22))\n",
    "\n",
    "for element in itertools.product(fn_c, fp_c):\n",
    "    plt.subplot(3,3,i)\n",
    "    for model, color in zip(models, colors):\n",
    "        fpr = 1 - np.array(precision_avg[model[0]])\n",
    "        fnr = 1 - np.array(recall_avg[model[0]])\n",
    "        cost = np.add(fpr * element[1], fnr * element[0])\n",
    "        plt.plot(costs, cost, \n",
    "                 color=color, label=model[0])\n",
    "        plt.xlabel(\"fn: %s fp:%s\" % (element[0], element[1]))\n",
    "        plt.xlim([2, 30])\n",
    "        plt.title(\"COST\")\n",
    "    i += 1\n",
    "\n",
    "    plt.ylabel(\"COST\")\n",
    "    plt.legend(loc='better')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Chaining PCA and Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "costs = np.arange(1, 21, 1)\n",
    "n_components = np.arange(1, 500, 25)\n",
    "recalls_pca = []\n",
    "precisions_pca = []\n",
    "\n",
    "data_pca = []\n",
    "\n",
    "#for element in itertools.product(costs, n_components):\n",
    "t0 = time.time()\n",
    "for element in itertools.product(costs, n_components):\n",
    "    bayes = BernoulliNB(class_prior=[1, element[0]])\n",
    "    pca = decomposition.PCA(n_components=element[1])\n",
    "    x_new = pca.fit_transform(extractor.transform(X).toarray())\n",
    "    bayes.fit(x_new, y)\n",
    "    recall = recall_score(y, bayes.predict(x_new))\n",
    "    precision = precision_score(y, bayes.predict(x_new))\n",
    "    data_pca.append((element[0], element[1], recall))\n",
    "    recalls_pca.append(recall)\n",
    "    precisions_pca.append(precision)\n",
    "t1 = time.time()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
