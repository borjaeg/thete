{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import collections\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "# Data Science\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Natural Language processing\n",
    "import nltk\n",
    "\n",
    "## Stemming\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Learning Algorithms / estimators\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Feature Extraction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Process\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Plotting\n",
    "from matplotlib.markers import MarkerStyle\n",
    "from PIL import Image\n",
    "\n",
    "# Corpus\n",
    "from documentModel import DocumentModel as DM\n",
    "from export_results import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_image(image, url='../images/', name = 'default'):\n",
    "    image.savefig(url + name)\n",
    "    Image.open(url + name + '.png').convert('L').save(url + name + '.png')\n",
    "    \n",
    "def plot_image(x, y, title=\"title\", ylim = [0, 1.02], xlim = [2, 50.5], \n",
    "               colors=\"rgbmyc\", models=None, name=\"name\", labels=[], ylabel = \"ylabel\", \n",
    "               loc=\"better\", markers=\".,ov<>\", pattern=\"\"):\n",
    "    plt.figure(figsize=(14,13))\n",
    "    plt.ylim(ylim)\n",
    "    plt.xlim(xlim)\n",
    "    plt.xlabel(\"Misclassification Cost Ratio\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.style.use('paper.mplstyle')\n",
    "    \n",
    "    filled_markers = ('<', 'D', 'o', '|', 'v', '>', 'p', 'd') #' '^', ', '>', '8', 's', 'p', '*', 'h', 'H', , 'd')\n",
    "    fillstyles = ('full', 'full', 'full', 'full', 'top', 'none')\n",
    "\n",
    "    i = 0\n",
    "    for model in models:\n",
    "        name = model[0]\n",
    "        if re.match(pattern, name) is not None:\n",
    "            plt.plot(x, y[name])\n",
    "            marker = MarkerStyle(marker=filled_markers[i], fillstyle=fillstyles[i])\n",
    "            plt.scatter(x, y[name], marker=marker, s=300, label=model[0])\n",
    "            i+=1\n",
    "    \n",
    "    plt.xticks(x, labels, rotation='vertical')\n",
    "    plt.legend(loc=loc, prop={'size':30})\n",
    "\n",
    "    save_image(plt,'../images/', name)\n",
    "    plt.show()\n",
    "    \n",
    "def filter_results(recalls, precisions, models=None, pattern=\".*\"):\n",
    "\n",
    "    recalls_avg = {}\n",
    "    precisions_avg = {}\n",
    "\n",
    "    for model in models:\n",
    "        name = model[0]\n",
    "        if re.match(pattern, name) is not None:\n",
    "            recalls_avg[name] = recalls[name]\n",
    "            precisions_avg[name] = precisions[name]\n",
    "    \n",
    "    return recalls_avg, precisions_avg\n",
    "    \n",
    "def normalize(recall_avg, precision_avg):\n",
    "    recall_avg_normalized = {}\n",
    "\n",
    "    for key, value in recall_avg.items():\n",
    "        recall_avg_normalized[key] = []\n",
    "\n",
    "    for key, values in recall_avg.items():\n",
    "        for value in values:\n",
    "            recall_avg_normalized[key].append(float(value * 100))\n",
    " \n",
    "\n",
    "    precision_avg_normalized = {}\n",
    "\n",
    "    for key, value in precision_avg.items():\n",
    "        precision_avg_normalized[key] = []\n",
    "\n",
    "    for key, values in precision_avg.items():\n",
    "        for value in values:\n",
    "            precision_avg_normalized[key].append(float(value * 100)) \n",
    "            \n",
    "    return recall_avg_normalized, precision_avg_normalized\n",
    "\n",
    "def set_baseline(name):\n",
    "    recall_baseline = recall_avg_normalized[name]\n",
    "    precision_baseline = precision_avg_normalized[name]\n",
    "    \n",
    "    return recall_baseline, precision_baseline\n",
    "\n",
    "#\".*Stemming.*(Bayes|SVM)\"    \n",
    "def summary(recalls, precisions, pattern=\".*\"):\n",
    "    r, p = filter_results(recalls, precisions, pipes, pattern) \n",
    "    max_recall = 0.0\n",
    "    best_precision = 0.0\n",
    "    best_cost = \"1:1\"\n",
    "    best_algorithm = ''\n",
    "\n",
    "    for (name, recalls), (name_2, precisions) in zip(r.items(), p.items()):\n",
    "        print(\"Executing: \" + name + \" ...\")\n",
    "        recs = []\n",
    "        pres = []\n",
    "        recs.append(np.mean(recalls))\n",
    "        pres.append(np.mean(precisions))\n",
    "        for i, (recall, precision) in enumerate(zip(recalls, precisions)):\n",
    "            if recall > max_recall:\n",
    "                best_cost = labels[i]\n",
    "                max_recall = recall\n",
    "                best_precision = precisions[i]\n",
    "                best_algorithm = name\n",
    "            if recall == max_recall and precision > best_precision:\n",
    "                best_cost = labels[i]\n",
    "                max_recall = recall\n",
    "                best_precision = precisions[i]\n",
    "                best_algorithm = name\n",
    "                \n",
    "    return best_cost, max_recall, best_precision, best_algorithm, np.mean(recs), np.mean(pres) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = SnowballStemmer(language=\"spanish\")\n",
    "    \n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.stem(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init():\n",
    "    recall_avg = {}\n",
    "    recall_std = {}\n",
    "    precision_avg = {}\n",
    "    precision_std = {}\n",
    "    pipelines = []\n",
    "\n",
    "    for element in itertools.product(estimators, nlp):\n",
    "        name = element[1][0] + '_' + element[0][0]\n",
    "        pipeline = Pipeline([('nlp', element[1][1]), ('clf', element[0][1])])\n",
    "        pipelines.append((name , pipeline))\n",
    "        recall_avg[name] = []\n",
    "        precision_avg[name] = []\n",
    "        recall_std[name] = []\n",
    "        precision_std[name] = []\n",
    "        \n",
    "    return pipelines, recall_avg, recall_std , precision_avg, precision_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Rule Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming annotated files into training datasets...\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "stop_words = ['a', 'bajo', 'en', 'para','un', 'la', 'el', 'los', 'las', 'su', 'sus', 'través', 'al','con', \\\n",
    "             'más', 'muy', 'cual', 'poco', 'que']\n",
    "\n",
    "print(\"Transforming annotated files into training datasets...\")\n",
    "dm = DM()\n",
    "fito_dataset = dm.get_sentences(0)\n",
    "X, y = fito_dataset[\"data\"], fito_dataset[\"target\"]\n",
    "\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rule_data = pd.DataFrame({\"rule\": X, \"tag\": y})\n",
    "permissions = rule_data[rule_data[\"tag\"] == 0]\n",
    "prohibitions = rule_data[rule_data[\"tag\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rule</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aplicar sobre el suelo en pequeños montones o ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aplicar en pulverización normal, variando la d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>En la etiqueta deberán figurar las instruccion...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Aplicar en pulverización normal, dependiendo d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Aplicar en pulverización normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 rule  tag\n",
       "0   Aplicar sobre el suelo en pequeños montones o ...    0\n",
       "3   Aplicar en pulverización normal, variando la d...    0\n",
       "4   En la etiqueta deberán figurar las instruccion...    0\n",
       "9   Aplicar en pulverización normal, dependiendo d...    0\n",
       "14                    Aplicar en pulverización normal    0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permissions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rule</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Evitar que el producto caiga sobre las plantas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Advertir en la etiqueta que es peligroso para ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>No mezclar con aceites ni productos de reacció...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>No aplicar aceites minerales durante los 21 dí...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>No aplicar en cultivos cuyos frutos sean desti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                rule  tag\n",
       "1  Evitar que el producto caiga sobre las plantas...    1\n",
       "2  Advertir en la etiqueta que es peligroso para ...    1\n",
       "5  No mezclar con aceites ni productos de reacció...    1\n",
       "6  No aplicar aceites minerales durante los 21 dí...    1\n",
       "7  No aplicar en cultivos cuyos frutos sean desti...    1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prohibitions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = [\"1:1\",\"1:2\",\"1:4\",\"1:6\",\"1:10\",\"1:25\", \"1:50\", r\"1:$10^2$\", r\"1:$10^3$\", r\"1:$10^6$\"]\n",
    "# like the ShuffleSplit strategy, stratified random splits do not guarantee \n",
    "#that all folds will be different, although this is still very likely for sizeable datasets\n",
    "sss = StratifiedKFold(y, n_folds = 10, random_state = 2016)\n",
    "costs = np.array([2, 3, 4, 6, 10, 25, 50, 100, 1000, 1000000])\n",
    "axis_costs = np.arange(1,11,1)\n",
    "cxlim = [0.8, 10.15]\n",
    "estimators = [(\"Naive Bayes\", MultinomialNB(fit_prior=False)), \n",
    "              (\"Random Forest\", RandomForestClassifier(n_estimators=20)), \n",
    "              (\"SVM\", SVC(kernel='linear', C = 0.1)),\n",
    "              (\"Baseline\", DummyClassifier(strategy = \"constant\", constant=1))]\n",
    "\n",
    "nlp = [(\"None\", TfidfVectorizer(use_idf = True, stop_words=stop_words)),\n",
    "       (\"Stemming\", TfidfVectorizer(use_idf = True, stop_words=stop_words, tokenizer=LemmaTokenizer())), \n",
    "       (\"Bigrams\", TfidfVectorizer(use_idf = True, stop_words=stop_words, ngram_range=(2, 2))), \n",
    "       (\"Combination\", TfidfVectorizer(use_idf = True, stop_words=stop_words, ngram_range=(1, 2)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipes, r_a, r_s, p_a, p_s = init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Experiment Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def experiment(pattern = \".*\", to_normalize = True):\n",
    "\n",
    "    t0 = time.time()\n",
    "    pipes, recall_avg, recall_std, precision_avg, precision_std = init()\n",
    "\n",
    "    for estimator in pipes:\n",
    "        name = estimator[0]\n",
    "        if re.match(pattern, name) is not None:\n",
    "            print(\"Trying: \" + name + \" ...\")\n",
    "            for cost in costs:\n",
    "                extractor = estimator[1].steps[0][1].fit(X)\n",
    "                if \"Naive Bayes\" in name:\n",
    "                    model = estimator[1].set_params(clf__class_prior=[1/cost, (cost-1)/cost]).steps[1][1]\n",
    "                elif \"Random Forest\" in name:\n",
    "                    model = estimator[1].set_params(clf__class_weight={1:cost-1}).steps[1][1]\n",
    "                elif \"SVM\" in name:\n",
    "                    model = estimator[1].set_params(clf__class_weight={1:cost-1}).steps[1][1]\n",
    "                elif \"Baseline\" in name:\n",
    "                    model = estimator[1].steps[1][1]\n",
    "            \n",
    "                precisions = []\n",
    "                recalls = []\n",
    "                for train_index, test_index in sss:\n",
    "                    X_train, X_test = \\\n",
    "                        extractor.transform(X)[train_index], extractor.transform(X)[test_index]\n",
    "                    y_train, y_test = y[train_index], y[test_index]\n",
    "                    model.fit(X_train, y_train)\n",
    "                    precisions.append(precision_score(y_test, model.predict(X_test), pos_label=1))\n",
    "                    recalls.append(recall_score(y_test, model.predict(X_test), pos_label=1))\n",
    "                recall_avg[name].append(np.average(recalls))\n",
    "                recall_std[name].append(np.std(recalls))\n",
    "                precision_avg[name].append(np.average(precisions))\n",
    "                precision_std[name].append(np.std(precisions))\n",
    "                \n",
    "    t1 = time.time()\n",
    "    print()\n",
    "    print(\"Execution time: %.3f min\" % ((t1 - t0)/60))\n",
    "    \n",
    "    if to_normalize == True:\n",
    "        recall_avg_normalized, precision_avg_normalized = normalize(recall_avg, precision_avg)\n",
    "        return recall_avg_normalized, precision_avg_normalized\n",
    "    \n",
    "    return recall_avg, precision_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying: None_Naive Bayes ...\n",
      "Trying: Stemming_Naive Bayes ...\n",
      "Trying: Bigrams_Naive Bayes ...\n",
      "Trying: Combination_Naive Bayes ...\n",
      "Trying: None_Random Forest ...\n",
      "Trying: Stemming_Random Forest ...\n",
      "Trying: Bigrams_Random Forest ...\n",
      "Trying: Combination_Random Forest ...\n",
      "Trying: None_SVM ...\n",
      "Trying: Stemming_SVM ...\n",
      "Trying: Bigrams_SVM ...\n",
      "Trying: Combination_SVM ...\n",
      "Trying: None_Baseline ...\n",
      "Trying: Stemming_Baseline ...\n",
      "Trying: Bigrams_Baseline ...\n",
      "Trying: Combination_Baseline ...\n",
      "\n",
      "Execution time: 10.084 min\n"
     ]
    }
   ],
   "source": [
    "recall_avg_normalized, precision_avg_normalized = experiment()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: Combination_Baseline ...\n",
      "Executing: Stemming_Naive Bayes ...\n",
      "Executing: None_Naive Bayes ...\n",
      "Executing: None_SVM ...\n",
      "Executing: Stemming_Random Forest ...\n",
      "Executing: Combination_Naive Bayes ...\n",
      "Executing: Stemming_SVM ...\n",
      "Executing: Bigrams_Naive Bayes ...\n",
      "Executing: None_Baseline ...\n",
      "Executing: None_Random Forest ...\n",
      "Executing: Bigrams_SVM ...\n",
      "Executing: Combination_Random Forest ...\n",
      "Executing: Bigrams_Random Forest ...\n",
      "Executing: Combination_SVM ...\n",
      "Executing: Stemming_Baseline ...\n",
      "Executing: Bigrams_Baseline ...\n"
     ]
    }
   ],
   "source": [
    "best_cost, max_recall, best_precision, best_algorithm, mean_recall, mean_precision = \\\n",
    "    summary(recall_avg_normalized, precision_avg_normalized, pattern=\".*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:10\n",
      "100.0\n",
      "44.718557180116036\n",
      "Bigrams_Naive Bayes\n",
      "100.0\n",
      "34.4986425339\n"
     ]
    }
   ],
   "source": [
    "print(best_cost)\n",
    "print(max_recall)\n",
    "print(best_precision)\n",
    "print(best_algorithm)\n",
    "print(mean_recall)\n",
    "print(mean_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: Combination_Naive Bayes ...\n",
      "Executing: Stemming_Naive Bayes ...\n",
      "Executing: None_Naive Bayes ...\n",
      "Executing: Bigrams_Naive Bayes ...\n"
     ]
    }
   ],
   "source": [
    "best_cost, max_recall, best_precision, best_algorithm, mean_recall, mean_precision = \\\n",
    "    summary(recall_avg_normalized, precision_avg_normalized, pattern=\".*Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:10\n",
      "100.0\n",
      "44.718557180116036\n",
      "Bigrams_Naive Bayes\n",
      "99.362745098\n",
      "45.8460064913\n"
     ]
    }
   ],
   "source": [
    "print(best_cost)\n",
    "print(max_recall)\n",
    "print(best_precision)\n",
    "print(best_algorithm)\n",
    "print(mean_recall)\n",
    "print(mean_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: Stemming_SVM ...\n",
      "Executing: Combination_SVM ...\n",
      "Executing: Bigrams_SVM ...\n",
      "Executing: None_SVM ...\n"
     ]
    }
   ],
   "source": [
    "best_cost, max_recall, best_precision, best_algorithm, mean_recall, mean_precision = \\\n",
    "    summary(recall_avg_normalized, precision_avg_normalized, pattern=\".*SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:6\n",
      "99.41176470588235\n",
      "51.59298770001042\n",
      "Bigrams_SVM\n",
      "92.2124183007\n",
      "68.7617875467\n"
     ]
    }
   ],
   "source": [
    "print(best_cost)\n",
    "print(max_recall)\n",
    "print(best_precision)\n",
    "print(best_algorithm)\n",
    "print(mean_recall)\n",
    "print(mean_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: None_Random Forest ...\n",
      "Executing: Combination_Random Forest ...\n",
      "Executing: Bigrams_Random Forest ...\n",
      "Executing: Stemming_Random Forest ...\n"
     ]
    }
   ],
   "source": [
    "best_cost, max_recall, best_precision, best_algorithm, mean_recall, mean_precision = \\\n",
    "    summary(recall_avg_normalized, precision_avg_normalized, pattern=\".*Random.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:$10^3$\n",
      "94.28104575163398\n",
      "75.94620997972726\n",
      "Bigrams_Random Forest\n",
      "86.6470588235\n",
      "84.8058127204\n"
     ]
    }
   ],
   "source": [
    "print(best_cost)\n",
    "print(max_recall)\n",
    "print(best_precision)\n",
    "print(best_algorithm)\n",
    "print(mean_recall)\n",
    "print(mean_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No preprocessing Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: None_Naive Bayes ...\n",
      "Executing: None_Random Forest ...\n",
      "Executing: None_SVM ...\n"
     ]
    }
   ],
   "source": [
    "best_cost, max_recall, best_precision, best_algorithm, mean_recall, mean_precision = \\\n",
    "    summary(recall_avg_normalized, precision_avg_normalized, pattern=\".*None.*(Bayes|SVM|.*Forest)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:25\n",
      "100.0\n",
      "44.00633773308192\n",
      "None_Naive Bayes\n",
      "92.2124183007\n",
      "68.7617875467\n"
     ]
    }
   ],
   "source": [
    "print(best_cost)\n",
    "print(max_recall)\n",
    "print(best_precision)\n",
    "print(best_algorithm)\n",
    "print(mean_recall)\n",
    "print(mean_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: Bigrams_SVM ...\n",
      "Executing: Bigrams_Random Forest ...\n",
      "Executing: Bigrams_Naive Bayes ...\n"
     ]
    }
   ],
   "source": [
    "best_cost, max_recall, best_precision, best_algorithm, mean_recall, mean_precision = \\\n",
    "    summary(recall_avg_normalized, precision_avg_normalized, pattern=\".*Bigra.*(Bayes|SVM|.*Forest)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:10\n",
      "100.0\n",
      "44.718557180116036\n",
      "Bigrams_Naive Bayes\n",
      "99.362745098\n",
      "45.8460064913\n"
     ]
    }
   ],
   "source": [
    "print(best_cost)\n",
    "print(max_recall)\n",
    "print(best_precision)\n",
    "print(best_algorithm)\n",
    "print(mean_recall)\n",
    "print(mean_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining bigrams and unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: Combination_Naive Bayes ...\n",
      "Executing: Combination_SVM ...\n",
      "Executing: Combination_Random Forest ...\n"
     ]
    }
   ],
   "source": [
    "best_cost, max_recall, best_precision, best_algorithm, mean_recall, mean_precision = \\\n",
    "    summary(recall_avg_normalized, precision_avg_normalized, pattern=\".*Comb.*(Bayes|SVM|.*Forest)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:25\n",
      "100.0\n",
      "44.251912831181116\n",
      "Combination_Naive Bayes\n",
      "88.4705882353\n",
      "81.6316299606\n"
     ]
    }
   ],
   "source": [
    "print(best_cost)\n",
    "print(max_recall)\n",
    "print(best_precision)\n",
    "print(best_algorithm)\n",
    "print(mean_recall)\n",
    "print(mean_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: Bigrams_SVM ...\n",
      "Executing: Bigrams_Naive Bayes ...\n",
      "Executing: Bigrams_Random Forest ...\n"
     ]
    }
   ],
   "source": [
    "plot_image(axis_costs, recall_avg_normalized, title=\"RECALL\", ylim = [80., 100.5], \n",
    "           xlim = cxlim, models=pipes, name=\"recall\", labels=labels, ylabel=\"Recall (%)\", \n",
    "           loc='lower righ', markers=\"<Do|\", pattern=\"(.*Bigram.*(Bayes|SVM|.*Forest)|None_Baseline)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_image(axis_costs, precision_avg_normalized, title=\"PRECISION\", ylim = [0., 100], \n",
    "           xlim = cxlim, colors=\"rgbmyc\", models=pipes, name=\"precision\", labels = labels, ylabel=\"Precision (%)\",\n",
    "           loc =\"lower right\", markers=\"<Do|\", pattern=\"(.*Bigram.*(Bayes|SVM|.*Forest)|None_Baseline)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
